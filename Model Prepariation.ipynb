{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Model Prepariation.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":["LMCH1DBW5IGW","ZmYYYKvW5IGf","yxa0_d5L5IHb","FMdtB-hl5IJb"],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ogok81ZP5H7E","colab_type":"code","colab":{}},"source":["from PIL import Image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eQaKNVIM5Oyg","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"rzJsHP-I5H73","colab_type":"code","colab":{}},"source":["# !unzip \"drive/My Drive/Q3 Noman Islam.zip\"\n","wor =  \"/content/Q3 Noman Islam\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vYrBOuflfCdg","colab_type":"code","colab":{}},"source":["!unzip '/content/drive/My Drive/Q3 Noman Islam.zip'\n","\n","!unzip 'train.zip'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5nmpyx75H8n","colab_type":"code","colab":{}},"source":["import os, shutil"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6jyrt2k85H9F","colab_type":"code","colab":{}},"source":["# original_dataset_dir = 'C:/Users/a.s.traders/Desktop/kaggle_original_data/train'\n","original_dataset_dir =  '/content/drive/My Drive/train'\n","!pwd\n","# %cd 'drive'\n","# %cd 'My Drive'\n","# %cd 'train'\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6eUIN24b9ygi","colab_type":"code","colab":{}},"source":["# !unzip \"drive/My Drive/Q3 Noman Islam.zip\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNScSWN65H9f","colab_type":"code","colab":{}},"source":["base_dir = 'D:Working_dire/'\n","os.mkdir(base_dir)\n","train_dir = os.path.join(base_dir, 'train')\n","os.mkdir(train_dir)\n","validation_dir = os.path.join(base_dir, 'validation')\n","os.mkdir(validation_dir)\n","test_dir = os.path.join(base_dir, 'test')\n","os.mkdir(test_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"od0V4r-B5H9-","colab_type":"code","colab":{}},"source":["train_cats_dir = os.path.join(train_dir, 'cats')\n","os.mkdir(train_cats_dir)\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","os.mkdir(train_dogs_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"des0Rcc-5H-X","colab_type":"code","colab":{}},"source":["validation_cats_dir = os.path.join(validation_dir, 'cats')\n","os.mkdir(validation_cats_dir)\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n","os.mkdir(validation_dogs_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ValB_Gr5H-u","colab_type":"code","colab":{}},"source":["test_cats_dir = os.path.join(test_dir, 'cats')\n","os.mkdir(test_cats_dir)\n","test_dogs_dir = os.path.join(test_dir, 'dogs')\n","os.mkdir(test_dogs_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pb9avCjD5H_F","colab_type":"text"},"source":["base_dir = 'D:/Working_dire/'\n","os.mkdir(base_dir)\n","train_dir = os.path.join(base_dir, 'train')\n","os.mkdir(train_dir)\n","validation_dir = os.path.join(base_dir, 'validation')\n","os.mkdir(validation_dir)\n","test_dir = os.path.join(base_dir, 'test')\n","os.mkdir(test_dir)\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","os.mkdir(train_cats_dir)\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","os.mkdir(train_dogs_dir)\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","os.mkdir(validation_cats_dir)\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n","os.mkdir(validation_dogs_dir)"]},{"cell_type":"code","metadata":{"id":"S0sUR0U85H_K","colab_type":"code","colab":{}},"source":["# !cat  'dog.55.jpg'\n","import os, shutil "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eSkp71nM5H_6","colab_type":"code","colab":{}},"source":["fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(train_cats_dir, fname)\n","    shutil.copyfile(src, dst)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vR0zF6tK5sa8","colab_type":"code","colab":{}},"source":["# base_dir = 'kaggle_original_data'\n","# os.mkdir(base_dir)\n","# train_dir = os.path.join(base_dir, 'train')\n","# os.mkdir(train_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JuJV6bbK5IAX","colab_type":"code","colab":{}},"source":["fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(validation_cats_dir, fname)\n","    shutil.copyfile(src, dst)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JwOPH3c55IAu","colab_type":"code","colab":{}},"source":["fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(test_cats_dir, fname)\n","    shutil.copyfile(src, dst)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbRpJQsG5IBF","colab_type":"code","colab":{}},"source":["fnames = ['dog.{}.jpg'.format(i) for i in range(2000,3000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(train_dogs_dir, fname)\n","    shutil.copyfile(src, dst)\n","\n","# fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n","# for fname in fnames:\n","    # src = os.path.join(original_dataset_dir, fname)\n","    # dst = os.path.join(validation_dogs_dir, fname)\n","    # shutil.copyfile(src, dst)\n","\n","# fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n","# for fname in fnames:\n","#     src = os.path.join(original_dataset_dir, fname)\n","#     dst = os.path.join(test_dogs_dir, fname)\n","#     shutil.copyfile(src, dst)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-R58NQRa5IBX","colab_type":"code","colab":{}},"source":["print('total training cat images:', len(os.listdir(train_cats_dir)))\n","# total training cat images: 1000\n","print('total training dog images:', len(os.listdir(train_dogs_dir)))\n","# total training dog images: 1000\n","print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n","# total validation cat images: 500\n","print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n","# total validation dog images: 500\n","print('total test cat images:', len(os.listdir(test_cats_dir)))\n","# total test cat images: 500\n","print('total test dog images:', len(os.listdir(test_dogs_dir)))\n","# total test dog images: 500"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bnda99O5IBv","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","\n","model = models.Sequential()\n","\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Flatten())\n","# Dence Classifier\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTnzN2Mu5ICC","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"twmJjEup5ICT","colab_type":"code","colab":{}},"source":["from tensorflow.keras import optimizers\n","model.compile(loss='binary_crossentropy',\n","optimizer=optimizers.RMSprop(lr=1e-4),\n","metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xdQldhNs5ICi","colab_type":"text"},"source":["# Using ImageDataGenerator to read images from directories"]},{"cell_type":"code","metadata":{"id":"SwVFlVNS5ICm","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LBTyzBjB5IC3","colab_type":"text"},"source":["RESCALING ALL IMAGES INTO 0-1"]},{"cell_type":"code","metadata":{"id":"71AEBt245IC7","colab_type":"code","colab":{}},"source":["train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rrBOwKAQ5IDZ","colab_type":"raw"},"source":["RESIZE ALL IMAGES AS 150X150"]},{"cell_type":"code","metadata":{"id":"vnckMXM-5IDc","colab_type":"code","colab":{}},"source":["train_generator = train_datagen.flow_from_directory (train_dir, target_size=(150, 150),\n","batch_size = 20,\n","class_mode='binary')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wfm0mD_M5IDs","colab_type":"code","colab":{}},"source":["validation_generator = test_datagen.flow_from_directory(\n","validation_dir,target_size=(150, 150),\n","batch_size=20,\n","class_mode='binary')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlUYXknl5ID1","colab_type":"code","colab":{}},"source":["# look at the output of one of these generators: it yields batches of 150 × 150 RGB images (shape (20, 150, 150, 3)) \n","# and binary labels (shape (20,)). There are 20 samples in each batch (the batch size). Note that the generator\n","# yields these batches indefinitely: it loops endlessly over the images in the target folder. For this reason, \n","# you need to break the iteration loop at some point:"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y4OQclv25ID-","colab_type":"code","colab":{}},"source":["for data_batch, labels_batch in train_generator:\n","    print('data batch shape:', data_batch.shape)\n","    print('labels batch shape:', labels_batch.shape)\n","    break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xo-mL_YQ5IEJ","colab_type":"text"},"source":["# # Fitting the model using a batch generator"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"oTtIQkyU5IEK","colab_type":"code","colab":{}},"source":["history = model.fit_generator   (train_generator,\n","steps_per_epoch=100,\n","epochs=30,\n","validation_data=validation_generator,\n","validation_steps=50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPGst2by5IEV","colab_type":"code","colab":{}},"source":["# Saving the model\n","Tyyar_model = model.save('usman.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KxIHWDzI5IEd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lp9r72cL5IEm","colab_type":"text"},"source":["#### Displaying curves of loss and accuracy during training\n"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"dlSQRLrN5IEn","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(acc) + 1)\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BvH8iBXC5IEw","colab_type":"text"},"source":["### Setting up a data augmentation configuration via ImageDataGenerator"]},{"cell_type":"code","metadata":{"id":"MNaEE4MsgTIf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SIigCUSh5IEy","colab_type":"code","colab":{}},"source":["datagen = ImageDataGenerator(  rotation_range=40,  width_shift_range=0.2,  height_shift_range=0.2,\n","shear_range=0.2,  zoom_range=0.2,  horizontal_flip=True,   fill_mode='nearest')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHa3RaVh5IE8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DWuDPzwThEN7","colab_type":"text"},"source":["Displaying some randomly augmented training images"]},{"cell_type":"code","metadata":{"id":"JmNZSnIZ5IFE","colab_type":"code","colab":{}},"source":["from keras.preprocessing import image    # Module with imagepreprocessing utilities\n","\n","fnames = [os.path.join(train_cats_dir, fname) for\n","fname in os.listdir(train_cats_dir)]\n","img_path = fnames[3]                         # Chooses one image to augment\n","img = image.load_img(img_path, target_size=(150, 150))  # Reads the image  and resizes it"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9mRKDzqk3aD","colab_type":"code","colab":{}},"source":["x = image.img_to_array(img)\n","x = x.reshape((1,) + x.shape)\n","i=0\n","for batch in datagen.flow(x, batch_size=1):\n","  plt.figure(i)\n","  imgplot = plt.imshow(image.array_to_img(batch[0]))\n","  i += 1\n","  if i % 8 == 0:\n","    break\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ch28hjqqgv2T","colab_type":"code","colab":{}},"source":["img"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xNQCQLZLlbOE","colab_type":"text"},"source":["Defining a new convnet that includes dropout"]},{"cell_type":"code","metadata":{"id":"7641CFoPliBa","colab_type":"code","colab":{}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu',\n","input_shape=(150, 150, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy',\n","optimizer=optimizers.RMSprop(lr=1e-4),\n","metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkc3B_JFlzIM","colab_type":"text"},"source":["4 Training the convnet using data-augmentation generators"]},{"cell_type":"code","metadata":{"id":"DsuiHpDJl2OE","colab_type":"code","colab":{}},"source":["train_datagen = ImageDataGenerator(  rescale=1./255,    rotation_range=40,      width_shift_range=0.2,\n","                                      height_shift_range=0.2,  shear_range=0.2,   zoom_range=0.2,\n","                                      horizontal_flip=True,)      \n","test_datagen = ImageDataGenerator(rescale=1./255)\n","train_generator = train_datagen.flow_from_directory( train_dir,    target_size=(150, 150),   batch_size=32,\n","class_mode='binary')\n","\n","validation_generator = test_datagen.flow_from_directory(  validation_dir,    target_size=(150, 150),   batch_size=32,\n","class_mode='binary')\n","\n","history = model.fit_generator( train_generator,   steps_per_epoch=100,  epochs=100,\n","validation_data=validation_generator,  validation_steps=50)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"15UqJaZCl2Ra","colab_type":"code","colab":{}},"source":["usman = model.save('usman_2.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_WQFMTml2LU","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(acc) + 1)\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4ribYga2kB1","colab_type":"code","colab":{}},"source":["from tensorflow.keras.applications import VGG16 \n","\n","vgg16 = VGG16(weights = 'imagenet',     include_top = False, input_shape = (150,150,3))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSu8i_ff2w_6","colab_type":"code","colab":{}},"source":["vgg16.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJEWxVlNHmFp","colab_type":"code","colab":{}},"source":["# import os\n","# import numpy as np\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","# original_dataset_dir =  'C:/Users/a.s traders/Desktop/kaggle_original_data/train'\n","# train_dir = os.path.join(base_dir, 'train')\n","# validation_dir = os.path.join(base_dir, 'validation')\n","# test_dir = os.path.join(base_dir, 'test')\n","# datagen = ImageDataGenerator(rescale=1./255)\n","# batch_size = 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IribzTGQI0aY","colab_type":"code","colab":{}},"source":["def extract_features(directory, sample_count):\n","    features = np.zeros(shape=(sample_count, 4, 4, 512))\n","    labels = np.zeros(shape=(sample_count))\n","    generator = datagen.flow_from_directory(directory,    target_size=(150, 150),  batch_size=batch_size, class_mode='binary')\n","    i=0\n","    for inputs_batch, labels_batch in generator:\n","        features_batch = vgg16.predict(inputs_batch)\n","        features[i * batch_size : (i + 1) * batch_size] = features_batch\n","        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n","        i += 1\n","        if i * batch_size >= sample_count:\n","            break\n","    return features, labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GcrmQky126KI","colab_type":"text"},"source":["Extracting features using the pretrained convolutional base"]},{"cell_type":"code","metadata":{"id":"yAGN0m_12ysj","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","original_dataset_dir =  '/content/drive/My Drive/train'\n","\n","# !ls\n","# %cd 'drive'\n","# %cd 'My Drive'\n","# %cd 'train'\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')\n","test_dir = os.path.join(base_dir, 'test')\n","datagen = ImageDataGenerator(rescale=1./255)\n","batch_size = 20\n","# def extract_features(directory, sample_count):\n","#   features = np.zeros(shape=(sample_count, 4, 4, 512))\n","#   labels = np.zeros(shape=(sample_count))\n","#   generator = datagen.flow_from_directory(  directory,  target_size=(150, 150),  batch_size=batch_size,\n","#                                           class_mode='binary')\n","#   i=0\n","#   for inputs_batch, labels_batch in generator:\n","#     features_batch = conv_base.predict(inputs_batch)\n","#     features[i * batch_size : (i + 1) * batch_size] = features_batch\n","#     labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n","#     i += 1\n","#     if i * batch_size >= sample_count:\n","#       break\n","#   return features, labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"adWHAI-s7GYE","colab_type":"code","colab":{}},"source":["train_features, train_labels = extract_features(train_dir, 2000)\n","validation_features, validation_labels = extract_features(validation_dir, 1000)\n","test_features, test_labels = extract_features(test_dir, 1000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECwquUeV7qYH","colab_type":"text"},"source":["The extracted features are currently of shape (samples, 4, 4, 512). You’ll feed them\n","to a densely connected classifier, so first you must flatten them to (samples, 8192):"]},{"cell_type":"code","metadata":{"id":"sjWkLaA97ny5","colab_type":"code","colab":{}},"source":["train_features = np.reshape(train_features, (2000, 4*4* 512))\n","validation_features = np.reshape(validation_features, (1000, 4*4* 512))\n","test_features = np.reshape(test_features, (1000, 4*4* 512))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vldkpEAD8G_n","colab_type":"text"},"source":["Defining and training the densely connected classifier"]},{"cell_type":"code","metadata":{"id":"KOpgKukm7sKk","colab_type":"code","colab":{}},"source":["from keras import models\n","from keras import layers\n","from keras import optimizers\n","model = models.Sequential()\n","model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n","loss='binary_crossentropy',\n","metrics=['acc'])\n","history = model.fit(train_features, train_labels,\n","epochs=30,\n","batch_size=20,\n","validation_data=(validation_features, validation_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y2BbuWUy7GoM","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(acc) + 1)\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UDk5ShAM8v-2","colab_type":"text"},"source":["0 Adding a densely connected classifier on top of the convolutional base"]},{"cell_type":"code","metadata":{"id":"F2btUxhq8adE","colab_type":"code","colab":{}},"source":["from keras import models\n","from keras import layers\n","model = models.Sequential()\n","model.add(layers(conv_base))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DT0Nfm248akZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wbsby3W8aiE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hg33ptMP2zCG","colab_type":"code","colab":{}},"source":["base_dir = 'D:Working_dire/'\n","os.mkdir(base_dir)\n","train_dir = os.path.join(base_dir, 'train')\n","os.mkdir(train_dir)\n","validation_dir = os.path.join(base_dir, 'validation')\n","os.mkdir(validation_dir)\n","test_dir = os.path.join(base_dir, 'test')\n","os.mkdir(test_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eANQiNch2zHk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NSlYlm-I5IFM","colab_type":"text"},"source":["### HOW TO PYTHON GENERATORS WORKS"]},{"cell_type":"code","metadata":{"id":"Jx_X7UhF5IFO","colab_type":"code","colab":{}},"source":["def square_number(nums):\n","    for i in nums:\n","        yield (i*i) # the word yield mak generator as function\n","square = square_number([1,2,3,4,5])\n","print(square)\n","\n","for nums in square:\n","    print(nums)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ay1qcFZq5IFY","colab_type":"code","colab":{}},"source":["square"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_-3ptg55IFh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXjc_i-R5IFr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpkBHjfb5IFz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbfgLKy35IF7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xFVyIRRp2Szm","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"gvGPUkvr5IGC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CXZFsG8z2SIh","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"gncSaRAg5IGJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1E9QiED5IGP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LMCH1DBW5IGW","colab_type":"text"},"source":["### Extracting features using the pretrained convolutional base"]},{"cell_type":"code","metadata":{"id":"pMNfzgfw5IGY","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","original_dataset_dir =  'C:/Users/a.s traders/Desktop/kaggle_original_data/train'\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')\n","test_dir = os.path.join(base_dir, 'test')\n","datagen = ImageDataGenerator(rescale=1./255)\n","batch_size = 20"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZmYYYKvW5IGf","colab_type":"text"},"source":["### Function"]},{"cell_type":"code","metadata":{"id":"_U2Ah-GZ5IGh","colab_type":"code","colab":{}},"source":["def extract_features(directory, sample_count):\n","    features = np.zeros(shape=(sample_count, 4, 4, 512))\n","    labels = np.zeros(shape=(sample_count))\n","    generator = datagen.flow_from_directory(directory,    target_size=(150, 150),  batch_size=batch_size, class_mode='binary')\n","    i=0\n","    for inputs_batch, labels_batch in generator:\n","        features_batch = vgg16.predict(inputs_batch)\n","        features[i * batch_size : (i + 1) * batch_size] = features_batch\n","        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n","        i += 1\n","        if i * batch_size >= sample_count:\n","            break\n","    return features, labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Th0gR0825IGo","colab_type":"code","colab":{}},"source":["train_features, train_labels = extract_features(train_dir, 2000)\n","validation_features, validation_labels = extract_features(validation_dir, 1000)\n","test_features, test_labels = extract_features(test_dir, 1000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1823Bsr5IHS","colab_type":"code","colab":{}},"source":["train_features = np.reshape(train_features, (2000, 4*4* 512))\n","validation_features = np.reshape(validation_features, (1000, 4*4* 512))\n","test_features = np.reshape(test_features, (1000, 4*4* 512))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yxa0_d5L5IHb","colab_type":"text"},"source":["### Defining and Training the Densely Connected Classifier"]},{"cell_type":"code","metadata":{"id":"AyNonBYR5IHc","colab_type":"code","colab":{}},"source":["from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","model = models.Sequential()\n","model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tY-Pr6_h5IHi","colab_type":"code","colab":{}},"source":["model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n","loss='binary_crossentropy',\n","metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_XA2PSz5IHq","colab_type":"code","colab":{}},"source":["history = model.fit (train_features,   train_labels,  \n","epochs=30,\n","batch_size=20,\n","validation_data=(validation_features, validation_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMoGgnqX5IHx","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(acc) + 1)\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"49TN9jir5IH9","colab_type":"code","colab":{}},"source":["model = models.Sequential()\n","model.add(vgg16)\n","model.add(layers.Flatten())\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FCnsEgS85IID","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1locKAnp5IIL","colab_type":"text"},"source":["Training the model end to end with a frozen convolutional base    Not that validation data should not be Augmanted"]},{"cell_type":"code","metadata":{"id":"Ku3TcoXo5IIN","colab_type":"code","colab":{}},"source":["train_datagen = ImageDataGenerator(\n","rescale=1./255,\n","rotation_range=40,\n","width_shift_range=0.2,\n","height_shift_range=0.2,\n","shear_range=0.2,\n","zoom_range=0.2,\n","horizontal_flip=True,\n","fill_mode='nearest')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IEE1UWP-5IIT","colab_type":"code","colab":{}},"source":["test_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SsGhzDpk5IIZ","colab_type":"code","colab":{}},"source":["train_generator = train_datagen.flow_from_directory(train_dir,   target_size=(150, 150),    batch_size=20,\n","class_mode='binary')\n","validation_generator = test_datagen.flow_from_directory(validation_dir,   target_size=(150, 150),  batch_size=20,\n","class_mode='binary')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTsZ4SKN5IIq","colab_type":"code","colab":{}},"source":["model.compile(loss='binary_crossentropy',\n","optimizer=optimizers.RMSprop(lr=2e-5),\n","metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuEbEv0U5IIw","colab_type":"code","colab":{}},"source":["history = model.fit_generator(\n","train_generator,\n","steps_per_epoch=100,\n","epochs=23,\n","validation_data=validation_generator,\n","validation_steps=50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EYhVVCHm5II3","colab_type":"code","colab":{}},"source":["vgg16.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqzi6Okg5II9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sl9Ttg5f5IJD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DbrRt58C5IJI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vi_CG8yg5IJO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-uGEs8o5IJU","colab_type":"code","colab":{}},"source":["model = Sequential()\n","#convolution-pooling layers\n","model.add(Convolution2D(32, 5, 5, input_shape=input_shape))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Convolution2D(64, 5, 5))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","#dense layers\n","model.add(Flatten()) \n","model.add(Dense(100))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add((Dense(2)))\n","model.add(Activation('softmax'))\n","#optimizer\n","sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True) \n","model.compile(loss='categorical_crossentropy',\n","              optimizer = sgd,\n","              metrics=['accuracy'])\n","print model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMdtB-hl5IJb","colab_type":"text"},"source":["# ### Step 1: Formula to calculate parameters\n","\n","    total_params =\n","    (filter_height * filter_width * input_image_channels + 1) * number_of_filters\n","\n","Step 2: Calculate parameters for first layer\n","\n","    filter_height = 5,\n","    filter_weight = 5,\n","    input_image_channels = 1\n","    number_of_filters = 32\n","    Though you havent provided us with imput image channels, but i figured it out from by your parameters value.\n","\n","Now we will calculate the number of parameters for first conv layer.\n","\n","    total_param = (5*5*1 + 1)*32 = 832\n"]},{"cell_type":"code","metadata":{"id":"1oxjFEaF5IJc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}